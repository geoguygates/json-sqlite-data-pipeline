import pandas as pd
import sqlite3
import os
from datetime import datetime
from config import ROOT_DIR, extract_bucket_pathname, transform_load_bucket_pathname

## Load all 4 extracted data frames from file folder

agreement_df = pd.read_parquet(f'{extract_bucket_pathname}\\agreement_df.parquet')
meterpoint_df = pd.read_parquet(f'{extract_bucket_pathname}\\meterpoint_df.parquet')
product_df = pd.read_parquet(f'{extract_bucket_pathname}\\product_df.parquet')
smart_meter_readings_df = pd.read_parquet(f'{extract_bucket_pathname}\\smart_meter_readings_df.parquet')

## Generate Table of all active agreements

agreement_product_df = agreement_df.merge(product_df, how='left', left_on=['product_id'], right_on = ['product_id'])

active_agreements_df = agreement_product_df.loc[((agreement_product_df['agreement_valid_from'] < '2021-01-01') & (agreement_product_df['agreement_valid_to'] > '2021-01-01') | (agreement_product_df['agreement_valid_to'].isnull()))].reset_index()

active_agreements_df = active_agreements_df[['agreement_id','meterpoint_id','display_name','is_variable']]

## Generate Table of the aggregate total consumption and count of meterpoints

agg_total_consumption_count_of_meterpoints_df = smart_meter_readings_df.groupby(['interval_start']).agg({'consumption_delta':'sum','meterpoint_id':'count'}).reset_index()

agg_total_consumption_count_of_meterpoints_df.columns = ['time', 'consumption_sum', 'meterpoint_count']

## Add a runtime column to each df so sql users know when the table data was generated by the pipeline

active_agreements_df['runtime'] = datetime.now()
agg_total_consumption_count_of_meterpoints_df['runtime'] = datetime.now()

## Write final analytics tables to sqlite db

connection = sqlite3.connect(f'{transform_load_bucket_pathname}\\final_analytics.db')

active_agreements_df.to_sql('active_agreements_df', connection, if_exists='append', index=False)
agg_total_consumption_count_of_meterpoints_df.to_sql('agg_total_consumption_count_of_meterpoints_df', connection, if_exists='append', index=False)
